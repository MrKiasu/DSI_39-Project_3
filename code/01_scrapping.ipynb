{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb961bd5",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10335e22",
   "metadata": {},
   "source": [
    "Data from the Department of Statistics show that annulments, marriage dissolutions, and Divorce rates in Singapore remain at an all-time high. In 2020 alone, 6,959 married couples filed for Divorce.\n",
    "\n",
    "Amongst multiple factors, communication with each other is top 4 reason for divorce. [https://blackbox.com.sg/everyone/honey-you-can-have-him-rising-divorce-in-singapore]\n",
    "\n",
    "How can we provide a low-barrier tool for people to better understand themselves and to be more mindful of their attachment styles?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5f24d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import praw\n",
    "import pandas as pd\n",
    "import gensim.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "009b696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API authentication. actual values redacted due to privacy.\n",
    "\n",
    "reddit_read_only = praw.Reddit(\n",
    "    client_id=\"client_id\",\n",
    "    client_secret=\"client_secret\",\n",
    "    user_agent=\"user_id,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77845dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the 2 subreddits, scrapping the top posts (up till 1,000)\n",
    "\n",
    "subreddit_name_A = \"AvoidantAttachment\"\n",
    "subreddit_name_B = \"AnxiousAttachment\"\n",
    "\n",
    "subreddit_A = reddit_read_only.subreddit(subreddit_name_A)\n",
    "subreddit_B = reddit_read_only.subreddit(subreddit_name_B)\n",
    "\n",
    "posts_A_top = subreddit_A.top(time_filter = \"all\", limit = None) \n",
    "posts_B_top = subreddit_B.top(time_filter = \"all\", limit = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e933dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize sets to store unique post IDs\n",
    "post_ids_A = set()\n",
    "post_ids_B = set()\n",
    "\n",
    "# Retrieve and process posts from subreddit_A\n",
    "posts_A = []\n",
    "\n",
    "# Convert the generators to lists\n",
    "top_posts_A = list(subreddit_A.top(time_filter=\"all\", limit=None))\n",
    "new_posts_A = list(subreddit_A.new(limit=None))\n",
    "\n",
    "# Merge the lists and remove duplicates based on post IDs\n",
    "merged_posts_A = top_posts_A + new_posts_A\n",
    "for post in merged_posts_A:\n",
    "    if post.id not in post_ids_A:\n",
    "        posts_A.append(post)\n",
    "        post_ids_A.add(post.id)\n",
    "\n",
    "# Retrieve and process posts from subreddit_B\n",
    "posts_B = []\n",
    "\n",
    "# Convert the generators to lists\n",
    "top_posts_B = list(subreddit_B.top(time_filter=\"all\", limit=None))\n",
    "new_posts_B = list(subreddit_B.new(limit=None))\n",
    "\n",
    "# Merge the lists and remove duplicates based on post IDs\n",
    "merged_posts_B = top_posts_B + new_posts_B\n",
    "for post in merged_posts_B:\n",
    "    if post.id not in post_ids_B:\n",
    "        posts_B.append(post)\n",
    "        post_ids_B.add(post.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3924564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the scrapping results into a dictionary\n",
    "\n",
    "posts_dictA = {\"Title\": [], \"Post Text\": [],\n",
    "              \"ID\": [], \"Score\": [],\n",
    "              \"Total Comments\": [], \"Post URL\": []\n",
    "              }\n",
    " \n",
    "for post in posts_A:\n",
    "    # Title of each post\n",
    "    posts_dictA[\"Title\"].append(post.title)\n",
    "     \n",
    "    # Text inside a post\n",
    "    posts_dictA[\"Post Text\"].append(post.selftext)\n",
    "     \n",
    "    # Unique ID of each post\n",
    "    posts_dictA[\"ID\"].append(post.id)\n",
    "     \n",
    "    # The score of a post\n",
    "    posts_dictA[\"Score\"].append(post.score)\n",
    "     \n",
    "    # Total number of comments inside the post\n",
    "    posts_dictA[\"Total Comments\"].append(post.num_comments)\n",
    "     \n",
    "    # URL of each post\n",
    "    posts_dictA[\"Post URL\"].append(post.url)\n",
    "\n",
    "posts_dictB = {\"Title\": [], \"Post Text\": [],\n",
    "              \"ID\": [], \"Score\": [],\n",
    "              \"Total Comments\": [], \"Post URL\": []\n",
    "              }\n",
    " \n",
    "for post in posts_B:\n",
    "    # Title of each post\n",
    "    posts_dictB[\"Title\"].append(post.title)\n",
    "     \n",
    "    # Text inside a post\n",
    "    posts_dictB[\"Post Text\"].append(post.selftext)\n",
    "     \n",
    "    # Unique ID of each post\n",
    "    posts_dictB[\"ID\"].append(post.id)\n",
    "     \n",
    "    # The score of a post\n",
    "    posts_dictB[\"Score\"].append(post.score)\n",
    "     \n",
    "    # Total number of comments inside the post\n",
    "    posts_dictB[\"Total Comments\"].append(post.num_comments)\n",
    "     \n",
    "    # URL of each post\n",
    "    posts_dictB[\"Post URL\"].append(post.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63351fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting scrapped posts from dictionary into a Dataframe, and assigning a class based on the subreddit.\n",
    "\n",
    "df_A = pd.DataFrame(posts_dictA)\n",
    "df_B = pd.DataFrame(posts_dictB)\n",
    "\n",
    "df_A[\"subreddit\"] = subreddit_name_A\n",
    "df_B[\"subreddit\"] = subreddit_name_B\n",
    "\n",
    "df_A[\"class\"] = 0\n",
    "df_B[\"class\"] = 1\n",
    "\n",
    "df = pd.concat([df_A, df_B], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2102fc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output the dataframe for the next section.\n",
    "\n",
    "df.to_csv(\"../data/df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ff1303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61fe35e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
