{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff58b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "854c0607",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f38b6dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Post Text</th>\n",
       "      <th>ID</th>\n",
       "      <th>Score</th>\n",
       "      <th>Total Comments</th>\n",
       "      <th>Post URL</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>378</td>\n",
       "      <td>If you love jumping to the worst scenario this...</td>\n",
       "      <td>I just typed most of this in a reply to anothe...</td>\n",
       "      <td>n02yto</td>\n",
       "      <td>68</td>\n",
       "      <td>13</td>\n",
       "      <td>https://www.reddit.com/r/AnxiousAttachment/com...</td>\n",
       "      <td>AnxiousAttachment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>882</td>\n",
       "      <td>Any APs who also have ADHD?</td>\n",
       "      <td>I feel like this combo is making it so much wo...</td>\n",
       "      <td>rs5yoo</td>\n",
       "      <td>37</td>\n",
       "      <td>30</td>\n",
       "      <td>https://www.reddit.com/r/AnxiousAttachment/com...</td>\n",
       "      <td>AnxiousAttachment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>861</td>\n",
       "      <td>Anyone else feel oddly soothed during this cra...</td>\n",
       "      <td>Usually when the person I'm actively intereste...</td>\n",
       "      <td>fmhsb2</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "      <td>https://www.reddit.com/r/AnxiousAttachment/com...</td>\n",
       "      <td>AnxiousAttachment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>276</td>\n",
       "      <td>the avoidant butt kissing here is annoying</td>\n",
       "      <td>Controversial post, but I don't mind. Luckily ...</td>\n",
       "      <td>uhikgx</td>\n",
       "      <td>81</td>\n",
       "      <td>44</td>\n",
       "      <td>https://www.reddit.com/r/AnxiousAttachment/com...</td>\n",
       "      <td>AnxiousAttachment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>855</td>\n",
       "      <td>Just started dating again. Scared and excited</td>\n",
       "      <td>He (33M) is secure, I am leaning secure. First...</td>\n",
       "      <td>qfdyyh</td>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>https://www.reddit.com/r/AnxiousAttachment/com...</td>\n",
       "      <td>AnxiousAttachment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>863</td>\n",
       "      <td>I dated someone for years off and on. I ended ...</td>\n",
       "      <td>**TL;DR:** I am a 28F AP who dated a 34M DA fo...</td>\n",
       "      <td>163p8je</td>\n",
       "      <td>37</td>\n",
       "      <td>43</td>\n",
       "      <td>https://www.reddit.com/r/AnxiousAttachment/com...</td>\n",
       "      <td>AnxiousAttachment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>912</td>\n",
       "      <td>What do you as a {da} do to better yourself?</td>\n",
       "      <td>Hey peeps! So I'm a dismissive avoidant, and I...</td>\n",
       "      <td>t9nvc7</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>https://www.reddit.com/r/AvoidantAttachment/co...</td>\n",
       "      <td>AvoidantAttachment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>239</td>\n",
       "      <td>{DA}{FA}{AP}{SA} How many anxious-avoidant dan...</td>\n",
       "      <td>I am realizing that not feeling defeated in th...</td>\n",
       "      <td>zi16bj</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.reddit.com/r/AvoidantAttachment/co...</td>\n",
       "      <td>AvoidantAttachment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>582</td>\n",
       "      <td>I'm a coach for folks with an anxious attachme...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ldmp1s</td>\n",
       "      <td>50</td>\n",
       "      <td>93</td>\n",
       "      <td>https://www.reddit.com/r/AnxiousAttachment/com...</td>\n",
       "      <td>AnxiousAttachment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>960</td>\n",
       "      <td>On letting go</td>\n",
       "      <td>Some food for thought from Lighter by Yung Pue...</td>\n",
       "      <td>ymzz51</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.reddit.com/r/AnxiousAttachment/com...</td>\n",
       "      <td>AnxiousAttachment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                              Title  \\\n",
       "1378         378  If you love jumping to the worst scenario this...   \n",
       "1882         882                        Any APs who also have ADHD?   \n",
       "1861         861  Anyone else feel oddly soothed during this cra...   \n",
       "1276         276         the avoidant butt kissing here is annoying   \n",
       "1855         855      Just started dating again. Scared and excited   \n",
       "1863         863  I dated someone for years off and on. I ended ...   \n",
       "912          912       What do you as a {da} do to better yourself?   \n",
       "239          239  {DA}{FA}{AP}{SA} How many anxious-avoidant dan...   \n",
       "1582         582  I'm a coach for folks with an anxious attachme...   \n",
       "1960         960                                      On letting go   \n",
       "\n",
       "                                              Post Text       ID  Score  \\\n",
       "1378  I just typed most of this in a reply to anothe...   n02yto     68   \n",
       "1882  I feel like this combo is making it so much wo...   rs5yoo     37   \n",
       "1861  Usually when the person I'm actively intereste...   fmhsb2     37   \n",
       "1276  Controversial post, but I don't mind. Luckily ...   uhikgx     81   \n",
       "1855  He (33M) is secure, I am leaning secure. First...   qfdyyh     39   \n",
       "1863  **TL;DR:** I am a 28F AP who dated a 34M DA fo...  163p8je     37   \n",
       "912   Hey peeps! So I'm a dismissive avoidant, and I...   t9nvc7     15   \n",
       "239   I am realizing that not feeling defeated in th...   zi16bj     43   \n",
       "1582                                                NaN   ldmp1s     50   \n",
       "1960  Some food for thought from Lighter by Yung Pue...   ymzz51     33   \n",
       "\n",
       "      Total Comments                                           Post URL  \\\n",
       "1378              13  https://www.reddit.com/r/AnxiousAttachment/com...   \n",
       "1882              30  https://www.reddit.com/r/AnxiousAttachment/com...   \n",
       "1861               8  https://www.reddit.com/r/AnxiousAttachment/com...   \n",
       "1276              44  https://www.reddit.com/r/AnxiousAttachment/com...   \n",
       "1855               6  https://www.reddit.com/r/AnxiousAttachment/com...   \n",
       "1863              43  https://www.reddit.com/r/AnxiousAttachment/com...   \n",
       "912               11  https://www.reddit.com/r/AvoidantAttachment/co...   \n",
       "239                2  https://www.reddit.com/r/AvoidantAttachment/co...   \n",
       "1582              93  https://www.reddit.com/r/AnxiousAttachment/com...   \n",
       "1960               2  https://www.reddit.com/r/AnxiousAttachment/com...   \n",
       "\n",
       "               subreddit  class  \n",
       "1378   AnxiousAttachment      1  \n",
       "1882   AnxiousAttachment      1  \n",
       "1861   AnxiousAttachment      1  \n",
       "1276   AnxiousAttachment      1  \n",
       "1855   AnxiousAttachment      1  \n",
       "1863   AnxiousAttachment      1  \n",
       "912   AvoidantAttachment      0  \n",
       "239   AvoidantAttachment      0  \n",
       "1582   AnxiousAttachment      1  \n",
       "1960   AnxiousAttachment      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e41be890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "# Selecting both the title and post text as the text to be analysed.\n",
    "\n",
    "df[\"text\"] = df[\"Title\"] + ' ' + df[\"Post Text\"].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5fd0115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0    1000\n",
       "1     998\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the number of rows for each class is similiar, i.e. no sign of class imbalance\n",
    "\n",
    "df[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffc780fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>A strange situation in 'behaving secure' journ...</td>\n",
       "      <td>a strange situation in behaving secure journey...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>Self Sabotage, Protest Behavior, and Deactivat...</td>\n",
       "      <td>self sabotage protest behavior and deactivatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>I'm so tired of being the bigger person {FA} I...</td>\n",
       "      <td>im so tired of being the bigger person fa ive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>This is why I have AA.</td>\n",
       "      <td>this is why i have aa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>{Da} If you broke up w/ someone, how did you k...</td>\n",
       "      <td>da if you broke up w someone how did you know ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "554   A strange situation in 'behaving secure' journ...   \n",
       "984   Self Sabotage, Protest Behavior, and Deactivat...   \n",
       "367   I'm so tired of being the bigger person {FA} I...   \n",
       "1904                            This is why I have AA.    \n",
       "276   {Da} If you broke up w/ someone, how did you k...   \n",
       "\n",
       "                                             text_clean  \n",
       "554   a strange situation in behaving secure journey...  \n",
       "984   self sabotage protest behavior and deactivatio...  \n",
       "367   im so tired of being the bigger person fa ive ...  \n",
       "1904                             this is why i have aa   \n",
       "276   da if you broke up w someone how did you know ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove punctuations and standardise to lowercase\n",
    "\n",
    "def remove_punct(text):\n",
    "    # store character only if it is not a punctuation\n",
    "    text_nopunct = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text_nopunct\n",
    "\n",
    "df[\"text_clean\"] = df[\"text\"].apply(lambda x: remove_punct(x.lower()))\n",
    "df[[\"text\", \"text_clean\"]].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "090fe91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>Healing and Sex: Once finally free of the addi...</td>\n",
       "      <td>healing and sex once finally free of the addic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>ah darn it lol</td>\n",
       "      <td>ah darn it lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>Anyone here have experience becoming more secu...</td>\n",
       "      <td>anyone here have experience becoming more secu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>{da} Fear of being 'bad' in bed? I mostly iden...</td>\n",
       "      <td>da fear of being bad in bed i mostly identify ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>They say deep down the truth is AA's are actua...</td>\n",
       "      <td>they say deep down the truth is aas are actual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>How do you get started on \"fixing\" avoidant at...</td>\n",
       "      <td>how do you get started on fixing avoidant atta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>A reminder from my journal … \\r\\nI deserve and...</td>\n",
       "      <td>a reminder from my journal … \\r\\ni deserve and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>I hate who I become in relationships {fa} I tu...</td>\n",
       "      <td>i hate who i become in relationships fa i turn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>I don't have a therapist. What do I do from he...</td>\n",
       "      <td>i dont have a therapist what do i do from here...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>To those who are hurt by an avoidant ex's beha...</td>\n",
       "      <td>to those who are hurt by an avoidant exs behav...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "1494  Healing and Sex: Once finally free of the addi...   \n",
       "1043                                    ah darn it lol    \n",
       "1180  Anyone here have experience becoming more secu...   \n",
       "793   {da} Fear of being 'bad' in bed? I mostly iden...   \n",
       "1560  They say deep down the truth is AA's are actua...   \n",
       "145   How do you get started on \"fixing\" avoidant at...   \n",
       "1542  A reminder from my journal … \\r\\nI deserve and...   \n",
       "129   I hate who I become in relationships {fa} I tu...   \n",
       "517   I don't have a therapist. What do I do from he...   \n",
       "1267  To those who are hurt by an avoidant ex's beha...   \n",
       "\n",
       "                                             text_clean  \n",
       "1494  healing and sex once finally free of the addic...  \n",
       "1043                                    ah darn it lol   \n",
       "1180  anyone here have experience becoming more secu...  \n",
       "793   da fear of being bad in bed i mostly identify ...  \n",
       "1560  they say deep down the truth is aas are actual...  \n",
       "145   how do you get started on fixing avoidant atta...  \n",
       "1542  a reminder from my journal … \\r\\ni deserve and...  \n",
       "129   i hate who i become in relationships fa i turn...  \n",
       "517   i dont have a therapist what do i do from here...  \n",
       "1267  to those who are hurt by an avoidant exs behav...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove urls in the text\n",
    "\n",
    "def remove_url(text):\n",
    "    text_nourl = re.sub(r'\\S*http\\S*', '', text)\n",
    "    return text_nourl\n",
    "\n",
    "df[\"text_clean\"] = df[\"text_clean\"].apply(lambda x: remove_url(x))\n",
    "\n",
    "df[[\"text\", \"text_clean\"]].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a743e342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>I don’t understand why I don’t express excitem...</td>\n",
       "      <td>i don’t understand why i don’t express excitem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>I bet a lot of anxious people are originally s...</td>\n",
       "      <td>i bet a lot of anxious people are originally s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>When your avoidant tendencies are triggered, h...</td>\n",
       "      <td>when your avoidant tendencies are triggered ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>Taylor Swift anxiously attached? During therap...</td>\n",
       "      <td>taylor swift anxiously attached during therapy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>I’m the problem I always thought I had a mild-...</td>\n",
       "      <td>i’m the problem i always thought i had a mildm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>If someone tells you who they are: BELIEVE THE...</td>\n",
       "      <td>if someone tells you who they are believe them...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>Set a boundary and got rejected. Trying to fee...</td>\n",
       "      <td>set a boundary and got rejected trying to feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>Is there any information on enmeshed/codepende...</td>\n",
       "      <td>is there any information on enmeshedcodependen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>A break off letter to my situationship of 9 mo...</td>\n",
       "      <td>a break off letter to my situationship of  mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>{fa} I think that many of us insecurely attach...</td>\n",
       "      <td>fa i think that many of us insecurely attached...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "195   I don’t understand why I don’t express excitem...   \n",
       "1385  I bet a lot of anxious people are originally s...   \n",
       "490   When your avoidant tendencies are triggered, h...   \n",
       "1826  Taylor Swift anxiously attached? During therap...   \n",
       "635   I’m the problem I always thought I had a mild-...   \n",
       "1048  If someone tells you who they are: BELIEVE THE...   \n",
       "1404  Set a boundary and got rejected. Trying to fee...   \n",
       "445   Is there any information on enmeshed/codepende...   \n",
       "1768  A break off letter to my situationship of 9 mo...   \n",
       "27    {fa} I think that many of us insecurely attach...   \n",
       "\n",
       "                                             text_clean  \n",
       "195   i don’t understand why i don’t express excitem...  \n",
       "1385  i bet a lot of anxious people are originally s...  \n",
       "490   when your avoidant tendencies are triggered ho...  \n",
       "1826  taylor swift anxiously attached during therapy...  \n",
       "635   i’m the problem i always thought i had a mildm...  \n",
       "1048  if someone tells you who they are believe them...  \n",
       "1404  set a boundary and got rejected trying to feel...  \n",
       "445   is there any information on enmeshedcodependen...  \n",
       "1768  a break off letter to my situationship of  mon...  \n",
       "27    fa i think that many of us insecurely attached...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove words that contain digit\n",
    "def remove_digit(text):\n",
    "    text_nodigit = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "    return text_nodigit\n",
    "\n",
    "df[\"text_clean\"] = df[\"text_clean\"].apply(lambda x: remove_digit(x))\n",
    "\n",
    "df[[\"text\", \"text_clean\"]].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fe0c3a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>Cool cool cool cool</td>\n",
       "      <td>[cool, cool, cool, cool, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>A Lasting Relationship Isn't Guaranteed (A Hea...</td>\n",
       "      <td>[a, lasting, relationship, isnt, guaranteed, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>Deactivating because life is hard {FA} I had t...</td>\n",
       "      <td>[deactivating, because, life, is, hard, fa, i,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>deactivation after moving in together {fa} My ...</td>\n",
       "      <td>[deactivation, after, moving, in, together, fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>{da} Advice on constant disappointment in inte...</td>\n",
       "      <td>[da, advice, on, constant, disappointment, in,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "1012                               Cool cool cool cool    \n",
       "1502  A Lasting Relationship Isn't Guaranteed (A Hea...   \n",
       "258   Deactivating because life is hard {FA} I had t...   \n",
       "798   deactivation after moving in together {fa} My ...   \n",
       "484   {da} Advice on constant disappointment in inte...   \n",
       "\n",
       "                                             text_token  \n",
       "1012                         [cool, cool, cool, cool, ]  \n",
       "1502  [a, lasting, relationship, isnt, guaranteed, a...  \n",
       "258   [deactivating, because, life, is, hard, fa, i,...  \n",
       "798   [deactivation, after, moving, in, together, fa...  \n",
       "484   [da, advice, on, constant, disappointment, in,...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize\n",
    "def tokenize(text):  \n",
    "    # /W matches any character that is neither alphanumeric nor underscoreb\n",
    "    # Add a + just in case there are 2 or more spaces between certain words\n",
    "    tokens = re.split('\\W+', text)\n",
    "    return tokens\n",
    "\n",
    "df[\"text_token\"] = df[\"text_clean\"].apply(lambda x: tokenize(x)) \n",
    "df[[\"text\", \"text_token\"]].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a604683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>{da} can a balance even exist on how much time...</td>\n",
       "      <td>[da, balance, even, exist, much, time, togethe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>Avoidant/anxious appreciation post Hey y’all! ...</td>\n",
       "      <td>[avoidantanxious, appreciation, post, hey, vit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>Anyone else see their avoidant ex on dating ap...</td>\n",
       "      <td>[anyone, else, see, avoidant, ex, dating, apps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>HOW to separate fear of intimacy from actually...</td>\n",
       "      <td>[separate, fear, intimacy, actually, wanting, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>Realized something in therapy today I (AA/ FA)...</td>\n",
       "      <td>[realized, something, therapy, today, aa, fa, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "654   {da} can a balance even exist on how much time...   \n",
       "1353  Avoidant/anxious appreciation post Hey y’all! ...   \n",
       "1552  Anyone else see their avoidant ex on dating ap...   \n",
       "633   HOW to separate fear of intimacy from actually...   \n",
       "1601  Realized something in therapy today I (AA/ FA)...   \n",
       "\n",
       "                                              text_stop  \n",
       "654   [da, balance, even, exist, much, time, togethe...  \n",
       "1353  [avoidantanxious, appreciation, post, hey, vit...  \n",
       "1552  [anyone, else, see, avoidant, ex, dating, apps...  \n",
       "633   [separate, fear, intimacy, actually, wanting, ...  \n",
       "1601  [realized, something, therapy, today, aa, fa, ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of default stopwords\n",
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# Remove stop words\n",
    "def remove_stopwords(tokenized_list):\n",
    "    #Store in text only if word is not found in stopword i.e. it is not a stopword\n",
    "    text = [word for word in tokenized_list if word not in stopword]\n",
    "    return text\n",
    "\n",
    "df[\"text_stop\"] = df[\"text_token\"].apply(lambda x: remove_stopwords(x))\n",
    "df[[\"text\", \"text_stop\"]].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cc24d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_lemmatise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>Anxious in relationships, but cold with my mom...</td>\n",
       "      <td>anxious relationship cold mom hi ask resonates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>A breakthrough in Anxious Attachment with ther...</td>\n",
       "      <td>breakthrough anxious attachment therapy wonder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Update: This sub remains restricted. It is sti...</td>\n",
       "      <td>update sub remains restricted still avoidant a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>How much longer do I have to try? I'm really t...</td>\n",
       "      <td>much longer try im really tired da hi im writi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>Undecided about dating {fa} I am constantly ch...</td>\n",
       "      <td>undecided dating fa constantly changing mind w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "1421  Anxious in relationships, but cold with my mom...   \n",
       "1274  A breakthrough in Anxious Attachment with ther...   \n",
       "51    Update: This sub remains restricted. It is sti...   \n",
       "968   How much longer do I have to try? I'm really t...   \n",
       "263   Undecided about dating {fa} I am constantly ch...   \n",
       "\n",
       "                                         text_lemmatise  \n",
       "1421  anxious relationship cold mom hi ask resonates...  \n",
       "1274  breakthrough anxious attachment therapy wonder...  \n",
       "51    update sub remains restricted still avoidant a...  \n",
       "968   much longer try im really tired da hi im writi...  \n",
       "263   undecided dating fa constantly changing mind w...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatizer\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "\n",
    "def lemmatizing(tokenized_text):\n",
    "    #return list of all lemmatized words for their corresponding words in tokenized_text\n",
    "    text = [wn.lemmatize(word) for word in tokenized_text]\n",
    "    return ' '.join(text)\n",
    "\n",
    "df[\"text_lemmatise\"] = df[\"text_stop\"].apply(lambda x: lemmatizing(x))\n",
    "df[[\"text\", \"text_lemmatise\"]].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd4b8c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Duplicate Words  Count (Class 0)  Count (Class 1)  Count Difference\n",
      "2192            coin                1                1                 0\n",
      "940              sum                1                1                 0\n",
      "1901              er                1                1                 0\n",
      "3688        mortgage                1                1                 0\n",
      "4526        creative                8                8                 0\n",
      "...              ...              ...              ...               ...\n",
      "4131         anxious              218              685               467\n",
      "1484            like             1791             1322               469\n",
      "2800            feel             1879             1310               569\n",
      "2716              im             1495              855               640\n",
      "3983              fa              743               81               662\n",
      "\n",
      "[5302 rows x 4 columns]\n",
      "(5302, 4)\n"
     ]
    }
   ],
   "source": [
    "# Separate the text into two lists based on class\n",
    "class_0_text = df[df['class'] == 0][\"text_clean\"].tolist()\n",
    "class_1_text = df[df['class'] == 1][\"text_clean\"].tolist()\n",
    "\n",
    "# Function to find and count duplicate words between both classes\n",
    "def find_duplicate_words_between_classes(df, column_name, class_column_name):\n",
    "    class_0_text = df[df[class_column_name] == 0][column_name].tolist()\n",
    "    class_1_text = df[df[class_column_name] == 1][column_name].tolist()\n",
    "    \n",
    "    all_words_class_0 = ' '.join(class_0_text).split()\n",
    "    all_words_class_1 = ' '.join(class_1_text).split()\n",
    "    \n",
    "    common_words = set(all_words_class_0).intersection(all_words_class_1)\n",
    "    \n",
    "    word_counts_class_0 = Counter(all_words_class_0)\n",
    "    word_counts_class_1 = Counter(all_words_class_1)\n",
    "    \n",
    "    top_common_words_class_0 = {word: word_counts_class_0[word] for word in common_words if word in word_counts_class_0}\n",
    "    top_common_words_class_1 = {word: word_counts_class_1[word] for word in common_words if word in word_counts_class_1}\n",
    "    \n",
    "    return pd.DataFrame({'Duplicate Words': list(common_words), \n",
    "                         'Count (Class 0)': [top_common_words_class_0.get(word, 0) for word in common_words],\n",
    "                         'Count (Class 1)': [top_common_words_class_1.get(word, 0) for word in common_words]})\n",
    "\n",
    "# Get the DataFrame containing duplicate words and counts for both classes\n",
    "duplicate_words_df = find_duplicate_words_between_classes(df, \"text_lemmatise\", \"class\")\n",
    "\n",
    "# Calculate the difference in counts between Class 0 and Class 1 for each word\n",
    "duplicate_words_df['Count Difference'] = (duplicate_words_df['Count (Class 0)'] - duplicate_words_df['Count (Class 1)']).abs()\n",
    "\n",
    "# Sort the DataFrame by the largest difference in counts (descending order)\n",
    "duplicate_words_df = duplicate_words_df.sort_values(by='Count Difference', ascending=True)\n",
    "\n",
    "# Display the duplicate words and counts for both classes\n",
    "print(duplicate_words_df)\n",
    "print(duplicate_words_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dedff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the list of duplicate words whose frequency in class 0/1 differed by less than 10 as additional stopwords to further clean the corpus\n",
    "\n",
    "additional_stopwords = duplicate_words_df[duplicate_words_df['Count Difference'].between(0, 10)]\n",
    "stopword += additional_stopwords[\"Duplicate Words\"].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7b0433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_final\"] = df[\"text_token\"].apply(lambda x: remove_stopwords(x))\n",
    "df[\"text_final\"] = df[\"text_final\"].apply(lambda x: lemmatizing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b44309e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>Are people actually prepared for us to change?...</td>\n",
       "      <td>people actually change fa avoidant think im gu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>Speaking of loving yourself {FA}</td>\n",
       "      <td>speaking fa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Weekly Video Discussion: Avoidant Attachment: ...</td>\n",
       "      <td>weekly discussion avoidant attachment keep rel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>breakup with a DA - before vs after</td>\n",
       "      <td>breakup da v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>This has helped me with my anxious attachment ...</td>\n",
       "      <td>helped anxious attachment first want send lot ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "377   Are people actually prepared for us to change?...   \n",
       "462                   Speaking of loving yourself {FA}    \n",
       "226   Weekly Video Discussion: Avoidant Attachment: ...   \n",
       "1185               breakup with a DA - before vs after    \n",
       "1682  This has helped me with my anxious attachment ...   \n",
       "\n",
       "                                             text_final  \n",
       "377   people actually change fa avoidant think im gu...  \n",
       "462                                        speaking fa   \n",
       "226   weekly discussion avoidant attachment keep rel...  \n",
       "1185                                      breakup da v   \n",
       "1682  helped anxious attachment first want send lot ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"text\", \"text_final\"]].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b043b465",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
